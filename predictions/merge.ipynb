{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1346718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy.typing import ArrayLike\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "885fce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PREDICTIONS = 10\n",
    "MIN_PROBABILITY = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eeeab840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the .npy files\n",
    "directories = [\n",
    "'./predictions/probabilities_submission_5h1l_tile_4_5_overlaps_0_0_use_gf_crop_010',\n",
    "'./predictions/probabilities_submission_hydra_5h1l_s_5h2l_gf_tile_45_00_usegf_crop10',\n",
    "]\n",
    "\n",
    "all_quadrat_probs: list[dict[str, ArrayLike]] = []\n",
    "\n",
    "for directory in directories:\n",
    "    # List to store the loaded data\n",
    "    quadrat_probs: dict[str, ArrayLike] = {}\n",
    "\n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.npy'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            quadrat_id = filename.split('.')[0]\n",
    "            tile_probabilities = np.load(file_path)\n",
    "\n",
    "            quadrat_probs[quadrat_id] = tile_probabilities\n",
    "\n",
    "    all_quadrat_probs.append(quadrat_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1427df5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import data\n",
    "\n",
    "plant_data_image_info, rare_species = data.get_plant_data_image_info(\n",
    "    os.path.join(\n",
    "        \"/mnt/storage1/shared_data/plant_clef_2025/\",\n",
    "        \"data/\",\n",
    "        \"plant_clef_train_281gb/\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "species_id_to_index = {\n",
    "            sid: idx\n",
    "            for idx, sid in enumerate(\n",
    "                sorted({info.species_id for info in plant_data_image_info})\n",
    "            )\n",
    "        }\n",
    "species_index_to_id = {idx: sid for sid, idx in species_id_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1aaa4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions: dict[str, list[int]] = {}\n",
    "\n",
    "assert all(quadrat_probs.keys() == all_quadrat_probs[0].keys() for quadrat_probs in all_quadrat_probs[1:]), \"All quadrat probabilities should have the same keys\"\n",
    "\n",
    "quadrat_probs = {quadrat_id: sum([quadrat_prob[quadrat_id] / len(all_quadrat_probs) for quadrat_prob in all_quadrat_probs]) for quadrat_id in all_quadrat_probs[0].keys()}\n",
    "\n",
    "for quadrat_id, tile_probabilities in quadrat_probs.items():\n",
    "    top_species = set()\n",
    "    for tile_idx, tile_probs in enumerate(tile_probabilities):\n",
    "        max_index = tile_probs.argmax()\n",
    "        if tile_probs[max_index] < MIN_PROBABILITY: continue\n",
    "        top_species.add(max_index)\n",
    "    image_predictions[quadrat_id] = list(top_species)\n",
    "    if len(image_predictions[quadrat_id]) == 0:\n",
    "        column_sums = np.sum(tile_probabilities, axis=0)\n",
    "        image_predictions[quadrat_id] = [column_sums.argmax()]\n",
    "    elif len(image_predictions[quadrat_id]) > MAX_PREDICTIONS:\n",
    "        column_sums = np.sum(tile_probabilities, axis=0)\n",
    "        relevant_sums = [column_sums[i] for i in image_predictions[quadrat_id]]\n",
    "        top_indices = np.argsort(relevant_sums)[-MAX_PREDICTIONS:]\n",
    "        image_predictions[quadrat_id] = [\n",
    "            list(image_predictions[quadrat_id])[i] for i in top_indices\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb6a5854",
   "metadata": {},
   "outputs": [],
   "source": [
    "for quadrat_id in image_predictions.keys():\n",
    "    image_predictions[quadrat_id] = [\n",
    "        species_index_to_id[idx] for idx in image_predictions[quadrat_id]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad7f5108",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_run = pd.DataFrame(\n",
    "    list(image_predictions.items()),\n",
    "    columns=[\n",
    "        \"quadrat_id\",\n",
    "        \"species_ids\",\n",
    "    ],\n",
    ")\n",
    "df_run[\"species_ids\"] = df_run[\"species_ids\"].apply(str)\n",
    "df_run.to_csv(\n",
    "    \"./predictions/submission.csv\",\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    quoting=csv.QUOTE_ALL,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
